{"ast":null,"code":"/**\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Code} Code\n */\nexport const resolver = {\n  resolveAll: createResolver()\n};\nexport const string = initializeFactory('string');\nexport const text = initializeFactory('text');\n/**\n * @param {'string'|'text'} field\n * @returns {InitialConstruct}\n */\n\nfunction initializeFactory(field) {\n  return {\n    tokenize: initializeText,\n    resolveAll: createResolver(field === 'text' ? resolveAllLineSuffixes : undefined)\n  };\n  /** @type {Initializer} */\n\n  function initializeText(effects) {\n    const self = this;\n    const constructs = this.parser.constructs[field];\n    const text = effects.attempt(constructs, start, notText);\n    return start;\n    /** @type {State} */\n\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code);\n    }\n    /** @type {State} */\n\n\n    function notText(code) {\n      if (code === null) {\n        effects.consume(code);\n        return;\n      }\n\n      effects.enter('data');\n      effects.consume(code);\n      return data;\n    }\n    /** @type {State} */\n\n\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit('data');\n        return text(code);\n      } // Data.\n\n\n      effects.consume(code);\n      return data;\n    }\n    /**\n     * @param {Code} code\n     * @returns {boolean}\n     */\n\n\n    function atBreak(code) {\n      if (code === null) {\n        return true;\n      }\n\n      const list = constructs[code];\n      let index = -1;\n\n      if (list) {\n        while (++index < list.length) {\n          const item = list[index];\n\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true;\n          }\n        }\n      }\n\n      return false;\n    }\n  }\n}\n/**\n * @param {Resolver} [extraResolver]\n * @returns {Resolver}\n */\n\n\nfunction createResolver(extraResolver) {\n  return resolveAllText;\n  /** @type {Resolver} */\n\n  function resolveAllText(events, context) {\n    let index = -1;\n    /** @type {number|undefined} */\n\n    let enter; // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === 'data') {\n          enter = index;\n          index++;\n        }\n      } else if (!events[index] || events[index][1].type !== 'data') {\n        // Don’t do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end;\n          events.splice(enter + 2, index - enter - 2);\n          index = enter + 2;\n        }\n\n        enter = undefined;\n      }\n    }\n\n    return extraResolver ? extraResolver(events, context) : events;\n  }\n}\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we can’t hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\n\n\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = -1;\n\n  while (++eventIndex <= events.length) {\n    if ((eventIndex === events.length || events[eventIndex][1].type === 'lineEnding') && events[eventIndex - 1][1].type === 'data') {\n      const data = events[eventIndex - 1][1];\n      const chunks = context.sliceStream(data);\n      let index = chunks.length;\n      let bufferIndex = -1;\n      let size = 0;\n      /** @type {boolean|undefined} */\n\n      let tabs;\n\n      while (index--) {\n        const chunk = chunks[index];\n\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length;\n\n          while (chunk.charCodeAt(bufferIndex - 1) === 32) {\n            size++;\n            bufferIndex--;\n          }\n\n          if (bufferIndex) break;\n          bufferIndex = -1;\n        } // Number\n        else if (chunk === -2) {\n            tabs = true;\n            size++;\n          } else if (chunk === -1) {// Empty\n          } else {\n            // Replacement character, exit.\n            index++;\n            break;\n          }\n      }\n\n      if (size) {\n        const token = {\n          type: eventIndex === events.length || tabs || size < 2 ? 'lineSuffix' : 'hardBreakTrailing',\n          start: {\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size,\n            _index: data.start._index + index,\n            _bufferIndex: index ? bufferIndex : data.start._bufferIndex + bufferIndex\n          },\n          end: Object.assign({}, data.end)\n        };\n        data.end = Object.assign({}, token.start);\n\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token);\n        } else {\n          events.splice(eventIndex, 0, ['enter', token, context], ['exit', token, context]);\n          eventIndex += 2;\n        }\n      }\n\n      eventIndex++;\n    }\n  }\n\n  return events;\n}","map":{"version":3,"sources":["/Users/rocknblock/Documents/GitHub/strong-hands-frontend/node_modules/micromark/lib/initialize/text.js"],"names":["resolver","resolveAll","createResolver","string","initializeFactory","text","field","tokenize","initializeText","resolveAllLineSuffixes","undefined","effects","self","constructs","parser","attempt","start","notText","code","atBreak","consume","enter","data","exit","list","index","length","item","previous","call","extraResolver","resolveAllText","events","context","type","end","splice","eventIndex","chunks","sliceStream","bufferIndex","size","tabs","chunk","charCodeAt","token","line","column","offset","_index","_bufferIndex","Object","assign"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMA,QAAQ,GAAG;AACtBC,EAAAA,UAAU,EAAEC,cAAc;AADJ,CAAjB;AAGP,OAAO,MAAMC,MAAM,GAAGC,iBAAiB,CAAC,QAAD,CAAhC;AACP,OAAO,MAAMC,IAAI,GAAGD,iBAAiB,CAAC,MAAD,CAA9B;AACP;AACA;AACA;AACA;;AAEA,SAASA,iBAAT,CAA2BE,KAA3B,EAAkC;AAChC,SAAO;AACLC,IAAAA,QAAQ,EAAEC,cADL;AAELP,IAAAA,UAAU,EAAEC,cAAc,CACxBI,KAAK,KAAK,MAAV,GAAmBG,sBAAnB,GAA4CC,SADpB;AAFrB,GAAP;AAMA;;AAEA,WAASF,cAAT,CAAwBG,OAAxB,EAAiC;AAC/B,UAAMC,IAAI,GAAG,IAAb;AACA,UAAMC,UAAU,GAAG,KAAKC,MAAL,CAAYD,UAAZ,CAAuBP,KAAvB,CAAnB;AACA,UAAMD,IAAI,GAAGM,OAAO,CAACI,OAAR,CAAgBF,UAAhB,EAA4BG,KAA5B,EAAmCC,OAAnC,CAAb;AACA,WAAOD,KAAP;AACA;;AAEA,aAASA,KAAT,CAAeE,IAAf,EAAqB;AACnB,aAAOC,OAAO,CAACD,IAAD,CAAP,GAAgBb,IAAI,CAACa,IAAD,CAApB,GAA6BD,OAAO,CAACC,IAAD,CAA3C;AACD;AACD;;;AAEA,aAASD,OAAT,CAAiBC,IAAjB,EAAuB;AACrB,UAAIA,IAAI,KAAK,IAAb,EAAmB;AACjBP,QAAAA,OAAO,CAACS,OAAR,CAAgBF,IAAhB;AACA;AACD;;AAEDP,MAAAA,OAAO,CAACU,KAAR,CAAc,MAAd;AACAV,MAAAA,OAAO,CAACS,OAAR,CAAgBF,IAAhB;AACA,aAAOI,IAAP;AACD;AACD;;;AAEA,aAASA,IAAT,CAAcJ,IAAd,EAAoB;AAClB,UAAIC,OAAO,CAACD,IAAD,CAAX,EAAmB;AACjBP,QAAAA,OAAO,CAACY,IAAR,CAAa,MAAb;AACA,eAAOlB,IAAI,CAACa,IAAD,CAAX;AACD,OAJiB,CAIhB;;;AAEFP,MAAAA,OAAO,CAACS,OAAR,CAAgBF,IAAhB;AACA,aAAOI,IAAP;AACD;AACD;AACJ;AACA;AACA;;;AAEI,aAASH,OAAT,CAAiBD,IAAjB,EAAuB;AACrB,UAAIA,IAAI,KAAK,IAAb,EAAmB;AACjB,eAAO,IAAP;AACD;;AAED,YAAMM,IAAI,GAAGX,UAAU,CAACK,IAAD,CAAvB;AACA,UAAIO,KAAK,GAAG,CAAC,CAAb;;AAEA,UAAID,IAAJ,EAAU;AACR,eAAO,EAAEC,KAAF,GAAUD,IAAI,CAACE,MAAtB,EAA8B;AAC5B,gBAAMC,IAAI,GAAGH,IAAI,CAACC,KAAD,CAAjB;;AAEA,cAAI,CAACE,IAAI,CAACC,QAAN,IAAkBD,IAAI,CAACC,QAAL,CAAcC,IAAd,CAAmBjB,IAAnB,EAAyBA,IAAI,CAACgB,QAA9B,CAAtB,EAA+D;AAC7D,mBAAO,IAAP;AACD;AACF;AACF;;AAED,aAAO,KAAP;AACD;AACF;AACF;AACD;AACA;AACA;AACA;;;AAEA,SAAS1B,cAAT,CAAwB4B,aAAxB,EAAuC;AACrC,SAAOC,cAAP;AACA;;AAEA,WAASA,cAAT,CAAwBC,MAAxB,EAAgCC,OAAhC,EAAyC;AACvC,QAAIR,KAAK,GAAG,CAAC,CAAb;AACA;;AAEA,QAAIJ,KAAJ,CAJuC,CAI7B;AACV;;AAEA,WAAO,EAAEI,KAAF,IAAWO,MAAM,CAACN,MAAzB,EAAiC;AAC/B,UAAIL,KAAK,KAAKX,SAAd,EAAyB;AACvB,YAAIsB,MAAM,CAACP,KAAD,CAAN,IAAiBO,MAAM,CAACP,KAAD,CAAN,CAAc,CAAd,EAAiBS,IAAjB,KAA0B,MAA/C,EAAuD;AACrDb,UAAAA,KAAK,GAAGI,KAAR;AACAA,UAAAA,KAAK;AACN;AACF,OALD,MAKO,IAAI,CAACO,MAAM,CAACP,KAAD,CAAP,IAAkBO,MAAM,CAACP,KAAD,CAAN,CAAc,CAAd,EAAiBS,IAAjB,KAA0B,MAAhD,EAAwD;AAC7D;AACA,YAAIT,KAAK,KAAKJ,KAAK,GAAG,CAAtB,EAAyB;AACvBW,UAAAA,MAAM,CAACX,KAAD,CAAN,CAAc,CAAd,EAAiBc,GAAjB,GAAuBH,MAAM,CAACP,KAAK,GAAG,CAAT,CAAN,CAAkB,CAAlB,EAAqBU,GAA5C;AACAH,UAAAA,MAAM,CAACI,MAAP,CAAcf,KAAK,GAAG,CAAtB,EAAyBI,KAAK,GAAGJ,KAAR,GAAgB,CAAzC;AACAI,UAAAA,KAAK,GAAGJ,KAAK,GAAG,CAAhB;AACD;;AAEDA,QAAAA,KAAK,GAAGX,SAAR;AACD;AACF;;AAED,WAAOoB,aAAa,GAAGA,aAAa,CAACE,MAAD,EAASC,OAAT,CAAhB,GAAoCD,MAAxD;AACD;AACF;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAEA,SAASvB,sBAAT,CAAgCuB,MAAhC,EAAwCC,OAAxC,EAAiD;AAC/C,MAAII,UAAU,GAAG,CAAC,CAAlB;;AAEA,SAAO,EAAEA,UAAF,IAAgBL,MAAM,CAACN,MAA9B,EAAsC;AACpC,QACE,CAACW,UAAU,KAAKL,MAAM,CAACN,MAAtB,IACCM,MAAM,CAACK,UAAD,CAAN,CAAmB,CAAnB,EAAsBH,IAAtB,KAA+B,YADjC,KAEAF,MAAM,CAACK,UAAU,GAAG,CAAd,CAAN,CAAuB,CAAvB,EAA0BH,IAA1B,KAAmC,MAHrC,EAIE;AACA,YAAMZ,IAAI,GAAGU,MAAM,CAACK,UAAU,GAAG,CAAd,CAAN,CAAuB,CAAvB,CAAb;AACA,YAAMC,MAAM,GAAGL,OAAO,CAACM,WAAR,CAAoBjB,IAApB,CAAf;AACA,UAAIG,KAAK,GAAGa,MAAM,CAACZ,MAAnB;AACA,UAAIc,WAAW,GAAG,CAAC,CAAnB;AACA,UAAIC,IAAI,GAAG,CAAX;AACA;;AAEA,UAAIC,IAAJ;;AAEA,aAAOjB,KAAK,EAAZ,EAAgB;AACd,cAAMkB,KAAK,GAAGL,MAAM,CAACb,KAAD,CAApB;;AAEA,YAAI,OAAOkB,KAAP,KAAiB,QAArB,EAA+B;AAC7BH,UAAAA,WAAW,GAAGG,KAAK,CAACjB,MAApB;;AAEA,iBAAOiB,KAAK,CAACC,UAAN,CAAiBJ,WAAW,GAAG,CAA/B,MAAsC,EAA7C,EAAiD;AAC/CC,YAAAA,IAAI;AACJD,YAAAA,WAAW;AACZ;;AAED,cAAIA,WAAJ,EAAiB;AACjBA,UAAAA,WAAW,GAAG,CAAC,CAAf;AACD,SAVD,CAUE;AAVF,aAWK,IAAIG,KAAK,KAAK,CAAC,CAAf,EAAkB;AACrBD,YAAAA,IAAI,GAAG,IAAP;AACAD,YAAAA,IAAI;AACL,WAHI,MAGE,IAAIE,KAAK,KAAK,CAAC,CAAf,EAAkB,CACvB;AACD,WAFM,MAEA;AACL;AACAlB,YAAAA,KAAK;AACL;AACD;AACF;;AAED,UAAIgB,IAAJ,EAAU;AACR,cAAMI,KAAK,GAAG;AACZX,UAAAA,IAAI,EACFG,UAAU,KAAKL,MAAM,CAACN,MAAtB,IAAgCgB,IAAhC,IAAwCD,IAAI,GAAG,CAA/C,GACI,YADJ,GAEI,mBAJM;AAKZzB,UAAAA,KAAK,EAAE;AACL8B,YAAAA,IAAI,EAAExB,IAAI,CAACa,GAAL,CAASW,IADV;AAELC,YAAAA,MAAM,EAAEzB,IAAI,CAACa,GAAL,CAASY,MAAT,GAAkBN,IAFrB;AAGLO,YAAAA,MAAM,EAAE1B,IAAI,CAACa,GAAL,CAASa,MAAT,GAAkBP,IAHrB;AAILQ,YAAAA,MAAM,EAAE3B,IAAI,CAACN,KAAL,CAAWiC,MAAX,GAAoBxB,KAJvB;AAKLyB,YAAAA,YAAY,EAAEzB,KAAK,GACfe,WADe,GAEflB,IAAI,CAACN,KAAL,CAAWkC,YAAX,GAA0BV;AAPzB,WALK;AAcZL,UAAAA,GAAG,EAAEgB,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB9B,IAAI,CAACa,GAAvB;AAdO,SAAd;AAgBAb,QAAAA,IAAI,CAACa,GAAL,GAAWgB,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkBP,KAAK,CAAC7B,KAAxB,CAAX;;AAEA,YAAIM,IAAI,CAACN,KAAL,CAAWgC,MAAX,KAAsB1B,IAAI,CAACa,GAAL,CAASa,MAAnC,EAA2C;AACzCG,UAAAA,MAAM,CAACC,MAAP,CAAc9B,IAAd,EAAoBuB,KAApB;AACD,SAFD,MAEO;AACLb,UAAAA,MAAM,CAACI,MAAP,CACEC,UADF,EAEE,CAFF,EAGE,CAAC,OAAD,EAAUQ,KAAV,EAAiBZ,OAAjB,CAHF,EAIE,CAAC,MAAD,EAASY,KAAT,EAAgBZ,OAAhB,CAJF;AAMAI,UAAAA,UAAU,IAAI,CAAd;AACD;AACF;;AAEDA,MAAAA,UAAU;AACX;AACF;;AAED,SAAOL,MAAP;AACD","sourcesContent":["/**\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Code} Code\n */\nexport const resolver = {\n  resolveAll: createResolver()\n}\nexport const string = initializeFactory('string')\nexport const text = initializeFactory('text')\n/**\n * @param {'string'|'text'} field\n * @returns {InitialConstruct}\n */\n\nfunction initializeFactory(field) {\n  return {\n    tokenize: initializeText,\n    resolveAll: createResolver(\n      field === 'text' ? resolveAllLineSuffixes : undefined\n    )\n  }\n  /** @type {Initializer} */\n\n  function initializeText(effects) {\n    const self = this\n    const constructs = this.parser.constructs[field]\n    const text = effects.attempt(constructs, start, notText)\n    return start\n    /** @type {State} */\n\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code)\n    }\n    /** @type {State} */\n\n    function notText(code) {\n      if (code === null) {\n        effects.consume(code)\n        return\n      }\n\n      effects.enter('data')\n      effects.consume(code)\n      return data\n    }\n    /** @type {State} */\n\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit('data')\n        return text(code)\n      } // Data.\n\n      effects.consume(code)\n      return data\n    }\n    /**\n     * @param {Code} code\n     * @returns {boolean}\n     */\n\n    function atBreak(code) {\n      if (code === null) {\n        return true\n      }\n\n      const list = constructs[code]\n      let index = -1\n\n      if (list) {\n        while (++index < list.length) {\n          const item = list[index]\n\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true\n          }\n        }\n      }\n\n      return false\n    }\n  }\n}\n/**\n * @param {Resolver} [extraResolver]\n * @returns {Resolver}\n */\n\nfunction createResolver(extraResolver) {\n  return resolveAllText\n  /** @type {Resolver} */\n\n  function resolveAllText(events, context) {\n    let index = -1\n    /** @type {number|undefined} */\n\n    let enter // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === 'data') {\n          enter = index\n          index++\n        }\n      } else if (!events[index] || events[index][1].type !== 'data') {\n        // Don’t do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end\n          events.splice(enter + 2, index - enter - 2)\n          index = enter + 2\n        }\n\n        enter = undefined\n      }\n    }\n\n    return extraResolver ? extraResolver(events, context) : events\n  }\n}\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we can’t hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\n\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = -1\n\n  while (++eventIndex <= events.length) {\n    if (\n      (eventIndex === events.length ||\n        events[eventIndex][1].type === 'lineEnding') &&\n      events[eventIndex - 1][1].type === 'data'\n    ) {\n      const data = events[eventIndex - 1][1]\n      const chunks = context.sliceStream(data)\n      let index = chunks.length\n      let bufferIndex = -1\n      let size = 0\n      /** @type {boolean|undefined} */\n\n      let tabs\n\n      while (index--) {\n        const chunk = chunks[index]\n\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length\n\n          while (chunk.charCodeAt(bufferIndex - 1) === 32) {\n            size++\n            bufferIndex--\n          }\n\n          if (bufferIndex) break\n          bufferIndex = -1\n        } // Number\n        else if (chunk === -2) {\n          tabs = true\n          size++\n        } else if (chunk === -1) {\n          // Empty\n        } else {\n          // Replacement character, exit.\n          index++\n          break\n        }\n      }\n\n      if (size) {\n        const token = {\n          type:\n            eventIndex === events.length || tabs || size < 2\n              ? 'lineSuffix'\n              : 'hardBreakTrailing',\n          start: {\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size,\n            _index: data.start._index + index,\n            _bufferIndex: index\n              ? bufferIndex\n              : data.start._bufferIndex + bufferIndex\n          },\n          end: Object.assign({}, data.end)\n        }\n        data.end = Object.assign({}, token.start)\n\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token)\n        } else {\n          events.splice(\n            eventIndex,\n            0,\n            ['enter', token, context],\n            ['exit', token, context]\n          )\n          eventIndex += 2\n        }\n      }\n\n      eventIndex++\n    }\n  }\n\n  return events\n}\n"]},"metadata":{},"sourceType":"module"}